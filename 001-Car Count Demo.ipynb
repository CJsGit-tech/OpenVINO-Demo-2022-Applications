{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20fb680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.vino_functions import PrepareNetWork,PrepareInputImage,MakePrediction\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d61f66",
   "metadata": {},
   "source": [
    "## Read In Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d761d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Model Input Dimension: 1 3 512 512\n"
     ]
    }
   ],
   "source": [
    "# Model Files\n",
    "model_root = Path('model/intel/person-vehicle-bike-detection-crossroad-1016/FP16-INT8')\n",
    "model_bin = model_root / 'person-vehicle-bike-detection-crossroad-1016.bin'\n",
    "model_xml = model_root / 'person-vehicle-bike-detection-crossroad-1016.xml'\n",
    "device = 'CPU'\n",
    "\n",
    "# Video Path\n",
    "video = 'data/15trim_highway_traffic.mp4'\n",
    "\n",
    "# Labels\n",
    "labels_map = {0:'non-vehicle',\n",
    "              1:'vehicle',\n",
    "              2:'person'}\n",
    "\n",
    "# Prepare Model\n",
    "car_detection_names, car_detection_exec_net, car_detection_img_shape = PrepareNetWork(model_xml,model_bin,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80a1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "## [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "\n",
    "def detection_box(result, output_key, prob_thresh, image,labels_map):\n",
    "    res = result[output_key].reshape(200,7)\n",
    "    height,width = image.shape[:2]\n",
    "    \n",
    "    detector = []\n",
    "    \n",
    "    \n",
    "    for obj in res:\n",
    "        conf = obj[2]\n",
    "        # Get Class ID\n",
    "        class_id = int(obj[1])\n",
    "        \n",
    "        if (conf >= prob_thresh) & (class_id in labels_map):\n",
    "            \n",
    "            # get coordinates\n",
    "            xmin = int(obj[3] * width)\n",
    "            ymin = int(obj[4] * height)\n",
    "            xmax = int(obj[5] * width)\n",
    "            ymax = int(obj[6] * height)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            # Draw Centroid\n",
    "            c_x = int((xmin+xmax) / 2)\n",
    "            c_y = int((ymin+ymax) / 2)\n",
    "            \n",
    "            detector.append((c_x,c_y))\n",
    "\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e342d84d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Video Reading utility \n",
    "cap = cv2.VideoCapture(video)\n",
    "car_cnt = 0\n",
    "\n",
    "# frame_name = 0\n",
    "while cap.isOpened():\n",
    "\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "#     frame_name += 1 \n",
    "    \n",
    "    if not ret:\n",
    "        # No Frames to render\n",
    "        break\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    image = frame[200:,640:]\n",
    "\n",
    "    \n",
    "    _, in_frame = PrepareInputImage(image,car_detection_img_shape)\n",
    "    result = MakePrediction(car_detection_exec_net,car_detection_names[0],in_frame)\n",
    "    detector = detection_box(result,car_detection_names[1], 0.7, image, labels_map)\n",
    "#     print(detector)\n",
    "    \n",
    "    roi_pt1 = (100,100)\n",
    "    roi_pt2 = (600,107)\n",
    "    \n",
    "\n",
    "    tracker_n = []\n",
    "    for id,val in enumerate(detector):\n",
    "        c_x,c_y = val\n",
    "        if roi_pt1[1] <= c_y <= roi_pt2[1]:\n",
    "            tracker_n.append((id,val))\n",
    "\n",
    "    for item in tracker_n:\n",
    "        id, pos = item\n",
    "\n",
    "\n",
    "        color = (0,255,125)\n",
    "        cv2.circle(image,pos,5,color,-1)\n",
    "        cv2.putText(image,text=f'{id}',org = (pos[0],pos[1]-10),\n",
    "                    fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale = 0.5, color = (0,0,255),\n",
    "                    thickness = 2, lineType = cv2.LINE_AA)\n",
    "\n",
    "        car_cnt+=1\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    fps = np.round(1/(end_time-start_time))\n",
    "    cv2.putText(image,text = f\"Current FPS: {fps}\",org = (0,30),\n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale = 0.5, color = (0,0,255),\n",
    "                thickness = 2, lineType = cv2.LINE_AA)\n",
    "    \n",
    "    cv2.putText(image,text = f\"Car Count: {car_cnt}\",org = (0,60),\n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale = 0.5, color = (0,255,255),\n",
    "                thickness = 2, lineType = cv2.LINE_AA)\n",
    "    \n",
    "    cv2.rectangle(image, roi_pt1, roi_pt2,(0,0,255),1)\n",
    "    \n",
    "    cv2.imshow('traffic', image)\n",
    "    \n",
    "#     cv2.imwrite(f\"frames/{str(frame_name).zfill(5)}.png\",image)\n",
    "\n",
    "    if cv2.waitKey(30) == ord('q'):\n",
    "        break\n",
    "\n",
    "        \n",
    "## Very Important to remeber to close all windows to avoid breakdown\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9aa17d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
